











import numpy as np
from sklearn import datasets # To load the dataset
from sklearn.model_selection import train_test_split # To split in train and test set

seed = 20
# Load the data and create the training and test sets
iris = datasets.load_iris()
# X is the feature vectors of the data points, and Y is the target (ground truth) class for those data points 
X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=seed) 





from matplotlib import pyplot as plt

# START ANSWER
plt.scatter(X_train[:,0], X_train[:,2], c=Y_train)
plt.show()
# END ANSWER








from scipy.spatial import distance

def euclidean(p, q):
    """
    Computes the Euclidean distance between point p and q.
    :param p: point p as a numpy array.
    :param q: point q as a numpy array.
    :return: distance as float.
    """
    
    dist = 0
    # START ANSWER
    dist = np.sqrt(np.dot(p-q, p-q))
    # END ANSWER
    return dist

# Check whether your algorithm is correct
a = np.array([2, 4, 8])
b = np.array([3, 5, 9])

print('The output of your algorithm:', euclidean(a, b))
assert np.isclose(euclidean(a, b), distance.euclidean(a, b))








def get_neighbours(training_set, test_instance, k):
    """
    Calculate distances from test_instance to all training points.
    :param training_set: [n x d] numpy array of training samples (n: number of samples, d: number of dimensions).
    :param test_instance: [d x 1] numpy array of test instance features.
    :param k: number of neighbours to return.
    :return: list of length k with neighbour indices, with increasing distance of the neighbours
    """
    
    neighbours = []
    # START ANSWER
    distances = [euclidean(x, test_instance) for x in training_set]
    neighbours = list(np.argsort(distances)[:k])

    """
    distances = {}
    for idx, point in enumerate(training_set):
        distances[idx] = euclidean(point, test_instance)
    neighbours = [key for key,v in sorted(distances.items(), key= lambda item: item[1])[:k]]
    """
    # END ANSWER
    return neighbours

neighbours = get_neighbours(X_train, X_test[0], 5)

# Check whether your algorithm is correct
print('The indices returned by your algorithm are:', neighbours)
assert neighbours == [63, 41, 76, 51, 10]





def plot_neighbours(X_train, Y_train, test_instance, k):
    """
    Plots all points in the dataset and shows the neighbours of a given test instance.
    """
    
    neighbours = get_neighbours(X_train, test_instance, k)
    # Initialization of the sizes of the points to be plotted, size 10 
    neigh_sizes = np.ones((len(Y_train), 1)) * 10
    neigh_sizes[neighbours] = 50
    plt.scatter(X_train[:, 0], X_train[:, 1], c=Y_train, s=neigh_sizes)
    plt.xlabel(iris.feature_names[0])
    plt.ylabel(iris.feature_names[1])
    plt.colorbar(ticks = [0, 1, 2], format = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)]));
    plt.scatter(test_instance[0], test_instance[1], c='r', s=50, marker='x')
    plt.show()

for i in range(3):
    test_instance = X_test[i, [0, 1]]
    k = 5
    plt.title('Test instance %s and its nearest neighbors' % (i+1))
    plot_neighbours(X_train[:, [0,1]], Y_train, test_instance, k)





from collections import Counter # To count unique occurrences of items in array, for majority voting

def get_majority_vote(neighbour_indices, training_labels):
    """
    Given an array of nearest neighbours indices for a given test case, 
    tally up their classes to vote on the correct class for the test instance.
    :param neighbours: list of nearest neighbour indices.
    :param training_labels: the list of labels for each training instance.
    :return: the label of most common class.
    """
    
    most_common = -1
    # START ANSWER
    labels = map(lambda x: training_labels[x], neighbour_indices)
    cnt = Counter(labels)
    max_votes = max(cnt.values())
    tied_labels = [label for label, value in cnt.items() if value == max_votes]

    for i in neighbour_indices:
        if training_labels[i] in tied_labels:
            return training_labels[i]
                   
    # END ANSWER
    return most_common

predicted_label = get_majority_vote(neighbours, Y_train)
print('Your predicted label:', predicted_label)
assert predicted_label == 0
assert get_majority_vote([0,1,2,3,4], [0,2,2,1,3]) == 2
assert get_majority_vote([0,1,2,3,4], [3,1,1,3,0]) == 3





from sklearn.metrics import accuracy_score

def predict(X_train, X_test, Y_train, k=5):
    """
    Predicts all labels for the test set, using k-nn on the training set.
    :param X_train: the training set features.
    :param X_test: the test set features.
    :param y_train: the training set labels.
    :return: list of predictions.
    """

    # Generate predictions
    predictions = []
    # For each instance in the test set, get nearest neighbours and majority vote on predicted class
    # START ANSWER
    [predictions.append(get_majority_vote(get_neighbours(X_train, x, k), Y_train)) for x in X_test]
    # END ANSWER
    return predictions

k = 5
predictions = predict(X_train, X_test, Y_train, k)

# Summarise performance of the classification using scikit-learn
accuracy = accuracy_score(Y_test, predictions)
print('The overall accuracy of the model using scikit-learn is:', accuracy)

assert predictions == [0, 1, 1, 2, 1, 1, 2, 0, 2, 0, 2, 1, 2, 0, 0, 2, 0, 1, 2, 1, 1, 2, 2, 0, 2, 1, 1, 0, 2, 2, 1, 1, 0, 0, 0, 1, 1, 0, 1, 2, 1, 2, 0, 1, 1, 0, 0, 0, 2, 0, 2, 2, 0, 2, 1, 1, 1, 0, 0, 1]
assert np.isclose(accuracy, 0.9666666666666667)





def accuracy_score_self(Y_test, predictions):
    """
    Computes the accuracy of a test set as the fraction of items that was classified correctly.
    :param y_test: the list of true labels for the test set.
    :param y_pred: the list of predicted labels for the test set.
    :return: accuracy as a floating point.
    """
    
    accuracy = 0
    # START ANSWER
    accuracy = len([1 for idx, label in enumerate(predictions) if label == Y_test[idx]]) / len(predictions)
    # END ANSWER
    return accuracy

# Summarise performance of the classification
accuracy_self = accuracy_score_self(Y_test, predictions)
print('The overall accuracy of the model using your implementation of accuracy:', accuracy_self)
assert np.isclose(accuracy, accuracy_self)





def plot_errors(X_train, X_test, Y_train, Y_test, predictions, k):
    """
    Plots the test points that were misclassified and their nearest neighbours using plot_neighbours.
    """
    
    # START ANSWER
    [plot_neighbours(X_train, Y_train, x, k)for x, y_pred, y_true in zip(X_test, predictions, Y_test) if y_pred != y_true]
    # END ANSWER
    return

plot_errors(X_train, X_test, Y_train, Y_test, predictions, k)





n_repetitions = 10
max_neighbours = 20
accuracies = np.zeros((max_neighbours, n_repetitions))
mean_accuracies = np.zeros(max_neighbours)
seeds = [x for x in range(n_repetitions)]

for i in range(n_repetitions):
    # Generate a new split of train and testset
    X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=seeds[i])
    for k in range(1, max_neighbours + 1):
    # START ANSWER
        predictions = [
            get_majority_vote(get_neighbours(X_train, x, k), Y_train)
            for x in X_test
        ]
        accuracies[k-1,i] = accuracy_score_self(Y_test, predictions)
mean_accuracies = np.mean(accuracies, axis=1)
# END ANSWER

plt.plot(range(1, 21), mean_accuracies)
plt.title('The averaged accuracies over the different values of k')
plt.xlabel('k')
plt.ylabel('Accuracy');








k = 9

X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=seed)

total_samples = X_train.shape[0]
# Set up array to store accuracies
accuracies = np.zeros(total_samples + 1)

# We want to learn with at least k samples and up to the size of the train set
for i in range(k, total_samples):
    predictions = predict(X_train[:i], X_test, Y_train[:i], k)
    accuracies[i + 1] = accuracy_score(Y_test, predictions)
    
# Plot learning curve
plt.plot(range(total_samples + 1), accuracies)
plt.title('The learning curve for the k-NN classifier')
plt.xlabel('Number of training samples')
plt.ylabel('Accuracy')
plt.show()





# 1) Train/test split using all 4 features and fit a KNN
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, classification_report

X = iris.data           # all 4 features
y = iris.target

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.4, random_state=42, stratify=y
)

# simple model selection for k using CV on the training set
k_grid = range(1, 21)
cv_scores = []
for k in k_grid:
    pipe = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=k))
    scores = cross_val_score(pipe, X_train, y_train, cv=5)
    cv_scores.append(scores.mean())

best_k = k_grid[int(np.argmax(cv_scores))]
print("Best k by CV:", best_k)

# fit final model
clf = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=best_k))
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
print("Test accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=iris.target_names))

# 2) Confusion matrix
from sklearn.metrics import ConfusionMatrixDisplay

ConfusionMatrixDisplay.from_predictions(
    y_test, y_pred, display_labels=iris.target_names, cmap="Blues", colorbar=False
)
plt.title(f"KNN (k={best_k}) confusion matrix")
plt.show()



# 3) Visualize in 2D with PCA: points + decision boundary in PCA space
from sklearn.decomposition import PCA
from sklearn.inspection import DecisionBoundaryDisplay

# Project data to 2D for plotting
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_scaled)

# Train a pipeline in PCA space for boundary visualization only
# Note: this is PCA(2) + KNN, which is a 2D approximation for visualization
pipe_pca2 = make_pipeline(
    StandardScaler(),           # re-scale in 2D space for KNN distance
    KNeighborsClassifier(n_neighbors=best_k)
)
pipe_pca2.fit(X_pca, y)

# Plot decision boundary on PCA(2)
fig, ax = plt.subplots(figsize=(6, 5))
DecisionBoundaryDisplay.from_estimator(
    pipe_pca2, X_pca, response_method="predict", ax=ax, alpha=0.2
)

# Overlay points, colored by true class
for cls, name in enumerate(iris.target_names):
    ax.scatter(
        X_pca[y == cls, 0], X_pca[y == cls, 1],
        label=name, s=25, edgecolor="none"
    )

ax.set_xlabel("PC1")
ax.set_ylabel("PC2")
ax.set_title(f"KNN decision regions in PCA(2) space (k={best_k})")
ax.legend()
plt.tight_layout()
plt.show()



import numpy as np
import matplotlib.pyplot as plt
from itertools import combinations
from collections import Counter
from sklearn import datasets

def euclidean(a, b):
    diff = a - b
    return float(np.sqrt(np.dot(diff, diff)))

def knn_predict_one(x, X_train, y_train, k):
    dists = [euclidean(x, p) for p in X_train]
    idx = np.argsort(dists)[:k]
    labels = [y_train[i] for i in idx]
    return Counter(labels).most_common(1)[0][0]

def knn_predict(X_test, X_train, y_train, k, verbose=False):
    preds = []
    n = len(X_test)
    for i, x in enumerate(X_test, start=1):
        preds.append(knn_predict_one(x, X_train, y_train, k))
        if verbose and i % (n // 5 + 1) == 0:  # print about 5 times
            print(f"  Processed {i}/{n} grid points…")
    return np.array(preds)

def plot_boundaries_all_features(X, y, feature_names, k=9, h=0.02):
    pairs = list(combinations(range(4), 2))
    plt.figure(figsize=(12, 9))

    for i, (f1, f2) in enumerate(pairs, start=1):
        print(f"\n[INFO] Processing pair {i}/{len(pairs)}: "
              f"{feature_names[f1]} vs {feature_names[f2]}")

        # Mesh grid for these two features
        x_min, x_max = X[:, f1].min() - 1, X[:, f1].max() + 1
        y_min, y_max = X[:, f2].min() - 1, X[:, f2].max() + 1
        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                             np.arange(y_min, y_max, h))

        grid_size = xx.size
        print(f"  Grid size: {grid_size} points")

        # Build full 4-D feature vectors
        base = np.tile(X.mean(axis=0), (grid_size, 1))
        base[:, f1] = xx.ravel()
        base[:, f2] = yy.ravel()

        print("  Classifying grid points…")
        Z = knn_predict(base, X, y, k, verbose=True)
        Z = Z.reshape(xx.shape)

        # Plot decision regions
        plt.subplot(2, 3, i)
        plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Set2)

        # Scatter actual data projected to selected features
        for class_val in np.unique(y):
            plt.scatter(X[y == class_val, f1],
                        X[y == class_val, f2],
                        label=f"Class {class_val}" if i == 1 else None,
                        edgecolor='k')

        plt.xlabel(feature_names[f1])
        plt.ylabel(feature_names[f2])
        plt.title(f"{feature_names[f1]} vs {feature_names[f2]}")

    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1))
    plt.tight_layout()
    print("\n[INFO] Rendering plots…")
    plt.show()

# Example usage
iris = datasets.load_iris()
X = iris.data
y = iris.target
feature_names = iris.feature_names

plot_boundaries_all_features(X, y, feature_names, k=9)



import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.neighbors import KernelDensity
from sklearn.model_selection import StratifiedKFold

# --- data: use features 0 and 2 (sepal length, petal length) ---
iris = datasets.load_iris()
X = iris.data[:, [0, 2]]
y = iris.target
classes = np.unique(y)

# --- fit one KDE per class ---
def fit_kdes(X, y, bandwidth=0.2, kernel="gaussian"):
    models = {}
    priors = {}
    for c in classes:
        Xc = X[y == c]
        kde = KernelDensity(bandwidth=bandwidth, kernel=kernel)
        kde.fit(Xc)
        models[c] = kde
        priors[c] = len(Xc) / len(X)
    return models, priors

# --- compute class posteriors P(c | x) using log-sum-exp for numerical stability ---
def posteriors(Xtest, models, priors):
    # log p(x|c) + log pi_c
    log_joint = []
    for c in classes:
        log_pc = models[c].score_samples(Xtest) + np.log(priors[c])
        log_joint.append(log_pc)
    log_joint = np.vstack(log_joint).T  # shape (n_samples, n_classes)

    # normalize to get posteriors
    # logsumexp over classes:
    m = np.max(log_joint, axis=1, keepdims=True)
    log_sum = m + np.log(np.sum(np.exp(log_joint - m), axis=1, keepdims=True))
    log_post = log_joint - log_sum
    return np.exp(log_post)  # shape (n_samples, n_classes)

# --- predict with reject option: "none" if max posterior < threshold ---
def predict_with_reject(Xtest, models, priors, threshold=0.5):
    P = posteriors(Xtest, models, priors)      # (n, 3)
    best_idx = np.argmax(P, axis=1)
    best_val = np.max(P, axis=1)
    preds = np.where(best_val < threshold, -1, best_idx)  # -1 means "none"
    return preds, P

# --- (optional) quick CV to pick bandwidth for classification accuracy with reject ---
def choose_bandwidth(X, y, bandwidth_grid, threshold=0.5, cv_splits=5, seed=42):
    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=seed)
    means = {}
    for bw in bandwidth_grid:
        accs = []
        for tr, va in cv.split(X, y):
            models, priors = fit_kdes(X[tr], y[tr], bandwidth=bw)
            preds, _ = predict_with_reject(X[va], models, priors, threshold=threshold)
            # Treat "none" as incorrect vs. true class labels
            accs.append(np.mean(preds == y[va]))
        means[bw] = float(np.mean(accs))
    best_bw = max(means, key=means.get)
    return best_bw, means

# --- train + plot ---
def plot_parzen_with_none(X, y, bandwidth=0.2, threshold=0.5, h=0.02):
    models, priors = fit_kdes(X, y, bandwidth=bandwidth)

    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    grid = np.c_[xx.ravel(), yy.ravel()]

    Z, P = predict_with_reject(grid, models, priors, threshold=threshold)
    Z = Z.reshape(xx.shape)

    # 4 classes: 0,1,2 plus -1 ("none")
    from matplotlib.colors import ListedColormap
    cmap = ListedColormap(["#A1D99B", "#9ECAE1", "#FDD0A2", "#CCCCCC"])  # last = grey for "none"
    plt.figure(figsize=(7, 6))
    plt.contourf(xx, yy, Z, alpha=0.35, cmap=cmap)

    # scatter true data
    for c, name in zip(classes, ["setosa", "versicolor", "virginica"]):
        plt.scatter(X[y == c, 0], X[y == c, 1], edgecolor="k", label=name)

    # legend entry for "none"
    plt.scatter([], [], color="#CCCCCC", edgecolor="k", label="none (reject)")

    plt.xlabel(iris.feature_names[0])
    plt.ylabel(iris.feature_names[2])
    plt.title(f"Parzen classifier with reject (τ=0.5), bandwidth={bandwidth}")
    plt.legend()
    plt.tight_layout()
    plt.show()

# ---- run it ----
# Optionally pick bandwidth by CV (with the reject rule baked into the scoring)
best_bw, scores = choose_bandwidth(X, y, bandwidth_grid=[0.05,0.1,0.2,0.3,0.5], threshold=0.5)
print("CV accuracies:", {bw: round(s,3) for bw,s in scores.items()})
print("Chosen bandwidth:", best_bw)

plot_parzen_with_none(X, y, bandwidth=best_bw, threshold=0.5)




